"""
Decoderå‡ºåŠ›ã®mask_logitsã‚’ç¢ºèª
"""
import torch
import sys
sys.path.insert(0, '.')
from savi_dinosaur import SAViDinosaur
from train_movi import MoviDataset
import numpy as np

# ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
checkpoint_path = '../checkpoints/twolayer_mlp_200ep/dinov2_vits14/best_model.pt'
checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)

model = SAViDinosaur(num_slots=5, backbone='dinov2_vits14', slot_dim=64)
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
dataset = MoviDataset('../data/movi_a_subset', split='all', max_frames=1)
sample = dataset[0]
video = sample['video'].unsqueeze(0)  # (1, T, 3, H, W)

print("="*80)
print("DECODER MASK LOGITS ANALYSIS")
print("="*80)

with torch.no_grad():
    # ãƒ•ãƒ«æ¨è«–ã§ã‚¹ãƒ­ãƒƒãƒˆã‚’å–å¾—
    features_proj, _ = model.encode(video[:, 0])
    slots = model.slot_attention(features_proj)  # (1, 5, 64)
    
    print(f"\nğŸ” Slots after Slot Attention:")
    print(f"  Shape: {slots.shape}")
    print(f"  Mean: {slots.mean().item():.6f}")
    print(f"  Std: {slots.std().item():.6f}")
    
    # ã‚¹ãƒ­ãƒƒãƒˆã‚’384æ¬¡å…ƒã«å¤‰æ›ã—ã¦Decoderã¸
    slots_upsampled = model.slot_to_feature(slots)  # (1, 5, 384)
    
    print(f"\nğŸ” Slots after upsampling to 384:")
    print(f"  Shape: {slots_upsampled.shape}")
    print(f"  Mean: {slots_upsampled.mean().item():.6f}")
    print(f"  Std: {slots_upsampled.std().item():.6f}")
   
    # ã‚¹ãƒ­ãƒƒãƒˆé–“ã®é¡ä¼¼åº¦
    slots_up_np = slots_upsampled[0].cpu().numpy()  # (5, 384)
    slot_up_similarities = []
    for i in range(5):
        for j in range(i + 1, 5):
            vec_i = slots_up_np[i]
            vec_j = slots_up_np[j]
            sim = np.dot(vec_i, vec_j) / (np.linalg.norm(vec_i) * np.linalg.norm(vec_j) + 1e-8)
            slot_up_similarities.append(sim)
    
    print(f"\nğŸ“Š Upsampled slot similarity:")
    print(f"  Mean: {np.mean(slot_up_similarities):.6f}")
    print(f"  Max: {np.max(slot_up_similarities):.6f}")
    print(f"  Min: {np.min(slot_up_similarities):.6f}")
    
    # Decoderã®æ‰‹å‹•å®Ÿè¡Œ
    b, k, d = slots_upsampled.shape
    h, w = model.decoder.resolution
    
    # Spatial Broadcast
    slots_2d = slots_upsampled.view(b * k, d, 1, 1).expand(-1, -1, h, w)
    grid = model.decoder.build_grid(b * k, slots_upsampled.device)
    
    decode_in = torch.cat([slots_2d, grid], dim=1)  # (5, 386, 16, 16)
    
    print(f"\nğŸ” Decoder input (slot + grid):")
    print(f"  Shape: {decode_in.shape}")
    print(f"  Mean: {decode_in.mean().item():.6f}")
    print(f"  Std: {decode_in.std().item():.6f}")
    
    # Decoderã‚’é€šã™
    out = model.decoder.decoder(decode_in)  # (5, 385, 16, 16)
    out = out.view(b, k, d + 1, h, w)  # (1, 5, 385, 16, 16)
    
    pred_feats = out[:, :, :d, :, :]  # (1, 5, 384, 16, 16)
    mask_logits = out[:, :, d:, :, :]  # (1, 5, 1, 16, 16)
    
    print(f"\nğŸ” Raw mask logits (before clipping):")
    print(f"  Shape: {mask_logits.shape}")
    print(f"  Mean: {mask_logits.mean().item():.6f}")
    print(f"  Std: {mask_logits.std().item():.6f}")
    print(f"  Min: {mask_logits.min().item():.6f}")
    print(f"  Max: {mask_logits.max().item():.6f}")
    
    # å„ã‚¹ãƒ­ãƒƒãƒˆã®logitsçµ±è¨ˆ
    mask_logits_np = mask_logits[0, :, 0].cpu().numpy()  # (5, 16, 16)
    print(f"\nğŸ“Š Per-slot mask logits:")
    for i in range(5):
        logits_i = mask_logits_np[i].flatten()
        print(f"  Slot {i}: mean={logits_i.mean():.4f}, std={logits_i.std():.4f}, min={logits_i.min():.4f}, max={logits_i.max():.4f}")
    
    # ã‚¹ãƒ­ãƒƒãƒˆé–“ã®logitsé¡ä¼¼åº¦
    logits_flat = mask_logits_np.reshape(5, -1)  # (5, 256)
    logit_similarities = []
    for i in range(5):
        for j in range(i + 1, 5):
            logit_i = logits_flat[i]
            logit_j = logits_flat[j]
            # Pearson correlation
            corr = np.corrcoef(logit_i, logit_j)[0, 1]
            logit_similarities.append(corr)
    
    print(f"\nğŸ“Š Mask logits correlation (before softmax):")
    print(f"  Mean: {np.mean(logit_similarities):.6f}")
    print(f"  Max: {np.max(logit_similarities):.6f}")
    print(f"  Min: {np.min(logit_similarities):.6f}")
    
    if np.mean(logit_similarities) > 0.95:
        print("\nâŒ CRITICAL: Decoder is producing nearly identical logits for all slots!")
        print("   The decoder is NOT differentiating between slots.")
        print("\n   Possible causes:")
        print("   1. Decoder is ignoring slot info, only using coordinate grid")
        print("   2. Upsampled slots (64â†’384) are too similar")
        print("   3. Decoder capacity insufficient")
    elif np.mean(logit_similarities) > 0.8:
        print("\nâš ï¸  WARNING: Mask logits are very similar across slots")
    else:
        print("\nâœ… OK: Decoder produces diverse logits")
    
    # Softmaxå¾Œ
    mask_logits_clipped = torch.clamp(mask_logits, min=-10, max=10)
    masks = torch.softmax(mask_logits_clipped, dim=1)  # (1, 5, 1, 16, 16)
    
    print(f"\nğŸ” After softmax:")
    print(f"  Masks shape: {masks.shape}")
    print(f"  Mean: {masks.mean().item():.6f}")
    print(f"  Std: {masks.std().item():.6f}")
    print(f"  Expected uniform: {1/5:.4f}")
    
    masks_np = masks[0, :, 0].cpu().numpy()
    print(f"\nğŸ“Š Per-slot mask coverage (after softmax):")
    for i in range(5):
        mask_i = masks_np[i].flatten()
        coverage = (mask_i > 0.1).sum() / len(mask_i)
        print(f"  Slot {i}: mean={mask_i.mean():.4f}, max={mask_i.max():.4f}, coverage>{0.1:.1f}={coverage:.1%}")
